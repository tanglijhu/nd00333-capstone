{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Azure resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from azureml.core.run import Run\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrive current run's information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Run.get_context()\n",
    "\n",
    "ws = run.experiment.workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = False\n",
    "key = \"heart-failure\"\n",
    "description_text = \"Clinical Record DataSet for Predicting Death Event\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        dataset = ws.datasets[key] \n",
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "\n",
    "    # Clean and one hot encode data\n",
    "    x_df = data.to_pandas_dataframe().dropna()\n",
    "\n",
    "\n",
    "    y_df = x_df.pop(\"DEATH_EVENT\")\n",
    "    return x_df , y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = clean_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Add arguments to script\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--C', type=float, default=1.0, help=\"Inverse of regularization strength. Smaller values cause stronger regularization\")\n",
    "    parser.add_argument('--max_iter', type=int, default=100, help=\"Maximum number of iterations to converge\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run.log(\"Regularization Strength:\", np.float(args.C))\n",
    "    run.log(\"Max iterations:\", np.int(args.max_iter))\n",
    "\n",
    "    model = LogisticRegression(C=args.C, max_iter=args.max_iter).fit(x_train, y_train)\n",
    "\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    run.log(\"Accuracy\", np.float(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
